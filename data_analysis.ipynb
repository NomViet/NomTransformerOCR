{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ccdead-d2c3-4e0c-a54a-a6b7c8e76271",
   "metadata": {},
   "source": [
    "## S·ªë l∆∞·ª£ng k√Ω t·ª± trong Train v√† Val dataset g·ªëc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c830ace-92e9-47b2-acd2-c5090e9e49da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Vocab\n",
    "\n",
    "train_vocab = set()\n",
    "\n",
    "with open(\"/bao/Nom-Viet/NomNaOCR/Datasets/Patches/Train.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        chars = parts[-1]\n",
    "        for ch in chars:\n",
    "            train_vocab.add(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ad0538b-0887-49ad-af63-eacd387aa344",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Val Vocab\n",
    "\n",
    "val_vocab = set()\n",
    "\n",
    "with open(\"/bao/Nom-Viet/NomNaOCR/Datasets/Patches/Validate.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        chars = parts[-1]\n",
    "        for ch in chars:\n",
    "            val_vocab.add(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc648411-2dc1-44b4-a40b-f345b0314cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total vocab - Train: 7174\n",
      "‚úÖ Total vocab - Val:   4956\n",
      "\n",
      "üî∏ S·ªë k√Ω t·ª± trong Val kh√¥ng c√≥ trong Train: 335\n",
      "C√°c k√Ω t·ª± b·ªã missing: \n",
      " ['Êèá', 'Áåó', 'Ê¢ê', 'ËäÄ', 'Ëøì', 'ÂÉ©', 'ÊïÑ', '¶Æé', '¢µØ', '\\U000f0634']\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Total vocab - Train:\", len(train_vocab))\n",
    "print(\"‚úÖ Total vocab - Val:  \", len(val_vocab))\n",
    "\n",
    "\n",
    "missing_in_train = val_vocab - train_vocab\n",
    "print(\"\\nüî∏ S·ªë k√Ω t·ª± trong Val kh√¥ng c√≥ trong Train:\", len(missing_in_train))\n",
    "print(\"C√°c k√Ω t·ª± b·ªã missing: \\n\", list(missing_in_train)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d0c8c8-e726-4488-b4c3-5b1859a1fa74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36774540-8b6e-4f18-b913-8ee0a783b610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH T·ªîNG H·ª¢P TRAIN + VALIDATE\n",
      "================================================================================\n",
      "\n",
      "ƒêang x·ª≠ l√Ω Train: /bao/Nom-Viet/NomNaOCR/Datasets/Patches/Train.txt...\n",
      "  ‚úì Train: 30654 ·∫£nh, 368441 k√Ω t·ª±\n",
      "\n",
      "ƒêang x·ª≠ l√Ω Validate: /bao/Nom-Viet/NomNaOCR/Datasets/Patches/Validate.txt...\n",
      "  ‚úì Validate: 7664 ·∫£nh, 91106 k√Ω t·ª±\n",
      "\n",
      "================================================================================\n",
      "--- TH·ªêNG K√ä T·ªîNG QUAN (TRAIN + VALIDATE) ---\n",
      "================================================================================\n",
      "‚úÖ T·ªïng s·ªë ·∫£nh: 38318\n",
      "‚úÖ T·ªïng s·ªë k√Ω t·ª±: 459547\n",
      "‚úÖ T·ªïng s·ªë vocab duy nh·∫•t: 7509\n",
      "\n",
      "‚úÖ ƒê√£ l∆∞u th·ªëng k√™ v√†o: vocab_stats.csv\n",
      "\n",
      "================================================================================\n",
      "TOP 20 K√ù T·ª∞ PH·ªî BI·∫æN NH·∫§T (theo T·ªïng s·ªë l·∫ßn xu·∫•t hi·ªán)\n",
      "================================================================================\n",
      "ky_tu | so_anh_chua  | ty_le_anh    | tong_so_lan_xuat_hien  | ty_le_tan_suat \n",
      "--------------------------------------------------------------------------------\n",
      "‰πã     | 6218         | 16.2274%     | 7638                   | 1.6621%        \n",
      "‰ª•     | 4396         | 11.4724%     | 4883                   | 1.0626%        \n",
      "‰∫∫     | 3239         | 8.4529%      | 3614                   | 0.7864%        \n",
      "Êúà     | 3210         | 8.3773%      | 3501                   | 0.7618%        \n",
      "ÂçÅ     | 3001         | 7.8318%      | 3312                   | 0.7207%        \n",
      "‰∏ç     | 2891         | 7.5448%      | 3201                   | 0.6966%        \n",
      "Âπ¥     | 2871         | 7.4926%      | 3036                   | 0.6607%        \n",
      "Â∏ù     | 2550         | 6.6548%      | 2737                   | 0.5956%        \n",
      "Êúâ     | 2374         | 6.1955%      | 2583                   | 0.5621%        \n",
      "‰∫å     | 2331         | 6.0833%      | 2534                   | 0.5514%        \n",
      "ÂÖ∂     | 2316         | 6.0442%      | 2507                   | 0.5455%        \n",
      "Â§ß     | 2246         | 5.8615%      | 2359                   | 0.5133%        \n",
      "Êó•     | 2150         | 5.6109%      | 2288                   | 0.4979%        \n",
      "ÁÇ∫     | 2013         | 5.2534%      | 2271                   | 0.4942%        \n",
      "Á≠â     | 1971         | 5.1438%      | 2104                   | 0.4578%        \n",
      "Áà≤     | 1803         | 4.7054%      | 2042                   | 0.4444%        \n",
      "ËÄå     | 1819         | 4.7471%      | 2015                   | 0.4385%        \n",
      "Âúã     | 1811         | 4.7262%      | 1988                   | 0.4326%        \n",
      "‰∏Ä     | 1804         | 4.7080%      | 1982                   | 0.4313%        \n",
      "Ëªç     | 1713         | 4.4705%      | 1915                   | 0.4167%        \n",
      "\n",
      "================================================================================\n",
      "PH√ÇN T√çCH B·ªî SUNG\n",
      "================================================================================\n",
      "üìä Vocab ch·ªâ c√≥ trong Train: 2553\n",
      "üìä Vocab ch·ªâ c√≥ trong Validate: 335\n",
      "üìä Vocab chung (Train ‚à© Validate): 4621\n",
      "üìä Vocab t·ªïng (Train ‚à™ Validate): 7509\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "# --- C·∫•u h√¨nh ---\n",
    "train_file = \"/bao/Nom-Viet/NomNaOCR/Datasets/Patches/Train.txt\"\n",
    "val_file = \"/bao/Nom-Viet/NomNaOCR/Datasets/Patches/Validate.txt\"\n",
    "output_csv_file = \"vocab_stats.csv\"\n",
    "\n",
    "# --- Kh·ªüi t·∫°o counters ---\n",
    "image_presence_counter = Counter()  # ƒê·∫øm k√Ω t·ª± c√≥ m·∫∑t trong bao nhi√™u ·∫£nh\n",
    "total_frequency_counter = Counter()  # ƒê·∫øm t·ªïng s·ªë l·∫ßn xu·∫•t hi·ªán\n",
    "total_images = 0\n",
    "total_characters = 0\n",
    "\n",
    "# --- H√†m x·ª≠ l√Ω file ---\n",
    "def process_file(file_path, file_name):\n",
    "    global total_images, total_characters\n",
    "    \n",
    "    print(f\"\\nƒêang x·ª≠ l√Ω {file_name}: {file_path}...\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            line_count = 0\n",
    "            char_count = 0\n",
    "            \n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                    \n",
    "                parts = line.split()\n",
    "                if len(parts) < 2:\n",
    "                    print(f\"  B·ªè qua d√≤ng kh√¥ng h·ª£p l·ªá: {line}\")\n",
    "                    continue\n",
    "                \n",
    "                line_count += 1\n",
    "                label = parts[-1]  # L·∫•y ph·∫ßn cu·ªëi c√πng l√†m nh√£n\n",
    "                \n",
    "                # ƒê·∫øm t·ªïng t·∫ßn su·∫•t\n",
    "                total_frequency_counter.update(label)\n",
    "                char_count += len(label)\n",
    "                \n",
    "                # ƒê·∫øm s·ª± hi·ªán di·ªán trong ·∫£nh\n",
    "                unique_chars_in_line = set(label)\n",
    "                image_presence_counter.update(unique_chars_in_line)\n",
    "            \n",
    "            total_images += line_count\n",
    "            total_characters += char_count\n",
    "            \n",
    "            print(f\"  ‚úì {file_name}: {line_count} ·∫£nh, {char_count} k√Ω t·ª±\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"  ‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng t√¨m th·∫•y file {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå L·ªói khi x·ª≠ l√Ω {file_name}: {e}\")\n",
    "\n",
    "# --- X·ª≠ l√Ω c·∫£ Train v√† Validate ---\n",
    "print(\"=\"*80)\n",
    "print(\"B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH T·ªîNG H·ª¢P TRAIN + VALIDATE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "process_file(train_file, \"Train\")\n",
    "process_file(val_file, \"Validate\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"--- TH·ªêNG K√ä T·ªîNG QUAN (TRAIN + VALIDATE) ---\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ T·ªïng s·ªë ·∫£nh: {total_images}\")\n",
    "print(f\"‚úÖ T·ªïng s·ªë k√Ω t·ª±: {total_characters}\")\n",
    "print(f\"‚úÖ T·ªïng s·ªë vocab duy nh·∫•t: {len(total_frequency_counter)}\")\n",
    "\n",
    "if total_images == 0 or total_characters == 0:\n",
    "    print(\"\\n‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ho·∫∑c file r·ªóng.\")\n",
    "else:\n",
    "    # --- T√≠nh to√°n th·ªëng k√™ ---\n",
    "    vocab = sorted(list(total_frequency_counter.keys()))\n",
    "    stats_list = []\n",
    "    \n",
    "    for char in vocab:\n",
    "        # S·ªë ·∫£nh ch·ª©a k√Ω t·ª± n√†y\n",
    "        img_count = image_presence_counter[char]\n",
    "        img_ratio = (img_count / total_images) * 100\n",
    "        \n",
    "        # T·ªïng s·ªë l·∫ßn xu·∫•t hi·ªán\n",
    "        freq_count = total_frequency_counter[char]\n",
    "        freq_ratio = (freq_count / total_characters) * 100\n",
    "        \n",
    "        stats_list.append([\n",
    "            char,\n",
    "            img_count,\n",
    "            f\"{img_ratio:.4f}%\",\n",
    "            freq_count,\n",
    "            f\"{freq_ratio:.4f}%\"\n",
    "        ])\n",
    "    \n",
    "    # S·∫Øp x·∫øp theo t·ªïng t·∫ßn su·∫•t (gi·∫£m d·∫ßn)\n",
    "    stats_list.sort(key=lambda x: x[3], reverse=True)\n",
    "    \n",
    "    # --- Ghi file CSV ---\n",
    "    header = [\n",
    "        \"ky_tu\",\n",
    "        \"so_anh_chua\",\n",
    "        \"ty_le_anh\",\n",
    "        \"tong_so_lan_xuat_hien\",\n",
    "        \"ty_le_tan_suat\"\n",
    "    ]\n",
    "    \n",
    "    with open(output_csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(stats_list)\n",
    "    \n",
    "    print(f\"\\n‚úÖ ƒê√£ l∆∞u th·ªëng k√™ v√†o: {output_csv_file}\")\n",
    "    \n",
    "    # --- Hi·ªÉn th·ªã Top 20 ---\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TOP 20 K√ù T·ª∞ PH·ªî BI·∫æN NH·∫§T (theo T·ªïng s·ªë l·∫ßn xu·∫•t hi·ªán)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{header[0]:<5} | {header[1]:<12} | {header[2]:<12} | {header[3]:<22} | {header[4]:<15}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for row in stats_list[:20]:\n",
    "        print(f\"{row[0]:<5} | {row[1]:<12} | {row[2]:<12} | {row[3]:<22} | {row[4]:<15}\")\n",
    "    \n",
    "    # --- Ph√¢n t√≠ch th√™m: Vocab ch·ªâ c√≥ trong Train ho·∫∑c Val ---\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PH√ÇN T√çCH B·ªî SUNG\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ƒê·ªçc l·∫°i ƒë·ªÉ ph√¢n t√≠ch ri√™ng\n",
    "    train_vocab = set()\n",
    "    with open(train_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                chars = parts[-1]\n",
    "                train_vocab.update(chars)\n",
    "    \n",
    "    val_vocab = set()\n",
    "    with open(val_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                chars = parts[-1]\n",
    "                val_vocab.update(chars)\n",
    "    \n",
    "    only_train = train_vocab - val_vocab\n",
    "    only_val = val_vocab - train_vocab\n",
    "    common = train_vocab & val_vocab\n",
    "    \n",
    "    print(f\"üìä Vocab ch·ªâ c√≥ trong Train: {len(only_train)}\")\n",
    "    if only_train and len(only_train) <= 20:\n",
    "        print(f\"   {sorted(only_train)}\")\n",
    "    \n",
    "    print(f\"üìä Vocab ch·ªâ c√≥ trong Validate: {len(only_val)}\")\n",
    "    if only_val and len(only_val) <= 20:\n",
    "        print(f\"   {sorted(only_val)}\")\n",
    "    \n",
    "    print(f\"üìä Vocab chung (Train ‚à© Validate): {len(common)}\")\n",
    "    print(f\"üìä Vocab t·ªïng (Train ‚à™ Validate): {len(train_vocab | val_vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a18d39-b8fb-4955-9306-aa68388f841c",
   "metadata": {},
   "source": [
    "## Merge vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25d5026c-0435-4d3b-9455-1f47b53f9c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·ªïng s·ªë l∆∞·ª£ng k√≠ t·ª± trong dataset:  7509\n"
     ]
    }
   ],
   "source": [
    "merge_vocab = val_vocab.union(train_vocab)\n",
    "print(\"T·ªïng s·ªë l∆∞·ª£ng k√≠ t·ª± trong dataset: \", len(merge_vocab))\n",
    "\n",
    "# L∆∞u vocab dict\n",
    "with open(\"dictionary_7k5.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for ch in sorted(merge_vocab):\n",
    "        f.write(ch + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f811f390-4406-4588-93f8-85220e5d60f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
